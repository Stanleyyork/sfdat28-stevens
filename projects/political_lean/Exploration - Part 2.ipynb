{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from goose import Goose\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from textblob import TextBlob, Word\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pld = pd.read_csv('0_12700.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>url_raw</th>\n",
       "      <th>url_clean</th>\n",
       "      <th>url_domain</th>\n",
       "      <th>ugly_text</th>\n",
       "      <th>issue</th>\n",
       "      <th>political_lean</th>\n",
       "      <th>title</th>\n",
       "      <th>meta_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UPDATE: Gov. Fallin vetoed the bill on Friday....</td>\n",
       "      <td>https://www.washingtonpost.com/news/post-natio...</td>\n",
       "      <td>washingtonpost.com/news/post-nation/wp/2016/05...</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>2         Desktop notifications are ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>‘A target on Roe v. Wade ’: Oklahoma bill maki...</td>\n",
       "      <td>Gov. Mary Fallin (R) has not said if she plans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>While the Hillary flap was merely a blip, give...</td>\n",
       "      <td>http://www.salon.com/2016/04/07/camille_paglia...</td>\n",
       "      <td>salon.com/2016/04/07/camille_paglia_feminists_...</td>\n",
       "      <td>salon.com</td>\n",
       "      <td>\\n\\n\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>Left</td>\n",
       "      <td>Camille Paglia: Feminists have abortion wrong,...</td>\n",
       "      <td>Reproductive rights have become ideological to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ever since Texas laws closed about half of the...</td>\n",
       "      <td>http://www.vox.com/2016/3/20/11269226/texas-ab...</td>\n",
       "      <td>vox.com/2016/3/20/11269226/texas-abortion-wome...</td>\n",
       "      <td>vox.com</td>\n",
       "      <td>\\n    \\n    \\n\\n(function(w,d,s,l,i){w[l]=w[l]...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Study: women had to drive 4 times farther afte...</td>\n",
       "      <td>Here's exactly how Texas anti-abortion laws bu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0  UPDATE: Gov. Fallin vetoed the bill on Friday....   \n",
       "1  While the Hillary flap was merely a blip, give...   \n",
       "2  Ever since Texas laws closed about half of the...   \n",
       "\n",
       "                                             url_raw  \\\n",
       "0  https://www.washingtonpost.com/news/post-natio...   \n",
       "1  http://www.salon.com/2016/04/07/camille_paglia...   \n",
       "2  http://www.vox.com/2016/3/20/11269226/texas-ab...   \n",
       "\n",
       "                                           url_clean          url_domain  \\\n",
       "0  washingtonpost.com/news/post-nation/wp/2016/05...  washingtonpost.com   \n",
       "1  salon.com/2016/04/07/camille_paglia_feminists_...           salon.com   \n",
       "2  vox.com/2016/3/20/11269226/texas-abortion-wome...             vox.com   \n",
       "\n",
       "                                           ugly_text     issue political_lean  \\\n",
       "0            2         Desktop notifications are ...  abortion      Lean Left   \n",
       "1  \\n\\n\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t...  abortion           Left   \n",
       "2  \\n    \\n    \\n\\n(function(w,d,s,l,i){w[l]=w[l]...  abortion      Lean Left   \n",
       "\n",
       "                                               title  \\\n",
       "0  ‘A target on Roe v. Wade ’: Oklahoma bill maki...   \n",
       "1  Camille Paglia: Feminists have abortion wrong,...   \n",
       "2  Study: women had to drive 4 times farther afte...   \n",
       "\n",
       "                                    meta_description  \n",
       "0  Gov. Mary Fallin (R) has not said if she plans...  \n",
       "1  Reproductive rights have become ideological to...  \n",
       "2  Here's exactly how Texas anti-abortion laws bu...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del pld[0]\n",
    "# cols = pld.columns.tolist()\n",
    "# cols = cols[-1:] + cols[:-1]\n",
    "# cols\n",
    "# pld = pld[cols]\n",
    "pld.columns = ['cleaned_text', 'url_raw', 'url_clean', 'url_domain', 'ugly_text', 'issue', 'political_lean', 'title', 'meta_description']\n",
    "pld.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_text      9830\n",
       "url_domain        9830\n",
       "political_lean    9830\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pld_text = pld[pld['cleaned_text'].notnull()]\n",
    "pld_text[['cleaned_text', 'url_domain', 'political_lean']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PIPELINE CAN ALSO BE USED WITH GRIDSEARCHCV, BUT VERY SLOW\n",
    "# pipe = Pipeline([\n",
    "#   ('features', FeatureUnion([\n",
    "#         ('counts', CountVectorizer()),\n",
    "#         ('tf_idf', TfidfVectorizer())\n",
    "#   ])),\n",
    "#   ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# SEARCH FOR AN OPTIMAL N_GRAM VALUE USING GRADSEARCHCV\n",
    "# gram_range = [(1, n) for n in range(1, 3)]\n",
    "# param_grid = {\n",
    "#     'features__counts__ngram_range': gram_range,\n",
    "#     'features__tf_idf__ngram_range': gram_range,\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "# grid.fit(df.msg, df.label)\n",
    "# print grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58514052559347773"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "cross_val_score(pipe, pld_text.cleaned_text, pld_text.political_lean, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49756282608223162"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer())\n",
    "  ])),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "cross_val_score(pipe, pld_text.cleaned_text, pld_text.political_lean, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587583794081\n",
      "0:08:32.436998\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer()),\n",
    "        ('tf_idf', TfidfVectorizer())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text.cleaned_text, pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496657158128\n",
      "0:01:25.248623\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer()),\n",
    "        ('tf_idf', TfidfVectorizer())\n",
    "  ])),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text.cleaned_text, pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Domain(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        domain_vect = CountVectorizer(max_features=60)\n",
    "        domains = pd.DataFrame(domain_vect.fit_transform(X.url_domain).toarray(), columns=domain_vect.get_feature_names())\n",
    "        print \"DomainVectorizer:\"\n",
    "        print domains.shape\n",
    "        return domains\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordVect(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        word_vect = CountVectorizer(max_features=5000)\n",
    "        words = pd.DataFrame(word_vect.fit_transform(X.cleaned_text).toarray(), columns=word_vect.get_feature_names())\n",
    "        print \"WordVectorizer:\"\n",
    "        print words.shape\n",
    "        return words\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordVectorizer:\n",
      "(7862, 5000)\n",
      "DomainVectorizer:\n",
      "(7862, 60)\n",
      "WordVectorizer:\n",
      "(7863, 5000)\n",
      "DomainVectorizer:\n",
      "(7863, 60)\n",
      "WordVectorizer:\n",
      "(1968, 5000)\n",
      "DomainVectorizer:\n",
      "(1968, 60)\n",
      "WordVectorizer:\n",
      "(7864, 5000)\n",
      "DomainVectorizer:\n",
      "(7864, 60)\n",
      "WordVectorizer:\n",
      "(1967, 5000)\n",
      "DomainVectorizer:\n",
      "(1967, 60)\n",
      "WordVectorizer:\n",
      "(7864, 5000)\n",
      "DomainVectorizer:\n",
      "(7864, 60)\n",
      "WordVectorizer:\n",
      "(1966, 5000)\n",
      "DomainVectorizer:\n",
      "(1966, 60)\n",
      "WordVectorizer:\n",
      "(1966, 5000)\n",
      "DomainVectorizer:\n",
      "(1966, 60)\n",
      "WordVectorizer:\n",
      "(7867, 5000)\n",
      "DomainVectorizer:\n",
      "(7867, 60)\n",
      "WordVectorizer:\n",
      "(1963, 5000)\n",
      "DomainVectorizer:\n",
      "(1963, 60)\n",
      "0.0245073801886\n",
      "0:00:31.749927\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('words', WordVect()),\n",
    "        ('domain', Domain())\n",
    "  ])),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pld_text['combined_feature'] = pld_text['cleaned_text'] + pld_text['url_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810270758743\n",
      "0:03:02.051172\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text['combined_feature'], pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973550495457\n",
      "0:00:00.725872\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text['url_domain'], pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977842377062\n",
      "0:00:01.987797\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld['url_domain'], pld.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833877222986\n",
      "1:08:38.473914\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer(ngram_range=(1,3)))\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text['combined_feature'], pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:stanleyyork]",
   "language": "python",
   "name": "conda-env-stanleyyork-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
