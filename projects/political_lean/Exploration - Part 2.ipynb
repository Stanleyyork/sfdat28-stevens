{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from goose import Goose\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from textblob import TextBlob, Word\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pld = pd.read_csv('0_16000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_raw</th>\n",
       "      <th>url_clean</th>\n",
       "      <th>url_domain</th>\n",
       "      <th>ugly_text</th>\n",
       "      <th>issue</th>\n",
       "      <th>political_lean</th>\n",
       "      <th>title</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.washingtonpost.com/news/post-natio...</td>\n",
       "      <td>washingtonpost.com/news/post-nation/wp/2016/05...</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>2         Desktop notifications are ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>‘A target on Roe v. Wade ’: Oklahoma bill maki...</td>\n",
       "      <td>Gov. Mary Fallin (R) has not said if she plans...</td>\n",
       "      <td>UPDATE: Gov. Fallin vetoed the bill on Friday....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.salon.com/2016/04/07/camille_paglia...</td>\n",
       "      <td>salon.com/2016/04/07/camille_paglia_feminists_...</td>\n",
       "      <td>salon.com</td>\n",
       "      <td>\\n\\n\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>Left</td>\n",
       "      <td>Camille Paglia: Feminists have abortion wrong,...</td>\n",
       "      <td>Reproductive rights have become ideological to...</td>\n",
       "      <td>While the Hillary flap was merely a blip, give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.vox.com/2016/3/20/11269226/texas-ab...</td>\n",
       "      <td>vox.com/2016/3/20/11269226/texas-abortion-wome...</td>\n",
       "      <td>vox.com</td>\n",
       "      <td>\\n    \\n    \\n\\n(function(w,d,s,l,i){w[l]=w[l]...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>Lean Left</td>\n",
       "      <td>Study: women had to drive 4 times farther afte...</td>\n",
       "      <td>Here's exactly how Texas anti-abortion laws bu...</td>\n",
       "      <td>Ever since Texas laws closed about half of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             url_raw  \\\n",
       "0  https://www.washingtonpost.com/news/post-natio...   \n",
       "1  http://www.salon.com/2016/04/07/camille_paglia...   \n",
       "2  http://www.vox.com/2016/3/20/11269226/texas-ab...   \n",
       "\n",
       "                                           url_clean          url_domain  \\\n",
       "0  washingtonpost.com/news/post-nation/wp/2016/05...  washingtonpost.com   \n",
       "1  salon.com/2016/04/07/camille_paglia_feminists_...           salon.com   \n",
       "2  vox.com/2016/3/20/11269226/texas-abortion-wome...             vox.com   \n",
       "\n",
       "                                           ugly_text     issue political_lean  \\\n",
       "0            2         Desktop notifications are ...  abortion      Lean Left   \n",
       "1  \\n\\n\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\t\\n\\t...  abortion           Left   \n",
       "2  \\n    \\n    \\n\\n(function(w,d,s,l,i){w[l]=w[l]...  abortion      Lean Left   \n",
       "\n",
       "                                               title  \\\n",
       "0  ‘A target on Roe v. Wade ’: Oklahoma bill maki...   \n",
       "1  Camille Paglia: Feminists have abortion wrong,...   \n",
       "2  Study: women had to drive 4 times farther afte...   \n",
       "\n",
       "                                    meta_description  \\\n",
       "0  Gov. Mary Fallin (R) has not said if she plans...   \n",
       "1  Reproductive rights have become ideological to...   \n",
       "2  Here's exactly how Texas anti-abortion laws bu...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  UPDATE: Gov. Fallin vetoed the bill on Friday....  \n",
       "1  While the Hillary flap was merely a blip, give...  \n",
       "2  Ever since Texas laws closed about half of the...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del pld['Unnamed: 0']\n",
    "pld.columns = ['url_raw', 'url_clean', 'url_domain', 'ugly_text', 'issue', 'political_lean', 'title', 'meta_description', 'cleaned_text']\n",
    "pld.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_text      12501\n",
       "url_domain        12501\n",
       "political_lean    12501\n",
       "issue             12501\n",
       "title             12462\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pld_text = pld[pld['cleaned_text'].notnull()]\n",
    "pld_text[['cleaned_text', 'url_domain', 'political_lean', 'issue', 'title']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PIPELINE CAN ALSO BE USED WITH GRIDSEARCHCV, BUT VERY SLOW\n",
    "# pipe = Pipeline([\n",
    "#   ('features', FeatureUnion([\n",
    "#         ('counts', CountVectorizer()),\n",
    "#         ('tf_idf', TfidfVectorizer())\n",
    "#   ])),\n",
    "#   ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# SEARCH FOR AN OPTIMAL N_GRAM VALUE USING GRADSEARCHCV\n",
    "# gram_range = [(1, n) for n in range(1, 3)]\n",
    "# param_grid = {\n",
    "#     'features__counts__ngram_range': gram_range,\n",
    "#     'features__tf_idf__ngram_range': gram_range,\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')\n",
    "# grid.fit(df.msg, df.label)\n",
    "# print grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.581698121969\n",
      "0:05:05.378078\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text.cleaned_text, pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.463778334447\n",
      "0:00:42.478829\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer())\n",
    "  ])),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text.cleaned_text, pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.587583794081\n",
      "0:08:32.436998\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer()),\n",
    "        ('tf_idf', TfidfVectorizer())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text.cleaned_text, pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496657158128\n",
      "0:01:25.248623\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer()),\n",
    "        ('tf_idf', TfidfVectorizer())\n",
    "  ])),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text.cleaned_text, pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Domain(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        domains = self.vect.transform(X.url_domain)\n",
    "        return domains\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.vect = CountVectorizer(**fit_params)\n",
    "        self.vect.fit(X['url_domain'])\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordVect(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        words = self.vect.transform(X.cleaned_text)\n",
    "        return words\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.vect = CountVectorizer(**fit_params)\n",
    "        self.vect.fit(X['cleaned_text'])\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordVectorizer:\n",
      "(9999, 57965)\n",
      "DomainVectorizer:\n",
      "(9999, 165)\n",
      "WordVectorizer:\n",
      "(10000, 58137)\n",
      "DomainVectorizer:\n",
      "(10000, 153)\n",
      "WordVectorizer:\n",
      "(10000, 58492)\n",
      "DomainVectorizer:\n",
      "(10000, 170)\n",
      "WordVectorizer:\n",
      "(10002, 57278)\n",
      "DomainVectorizer:\n",
      "(10002, 157)\n",
      "WordVectorizer:\n",
      "(2502, 57965)\n",
      "DomainVectorizer:\n",
      "(2502, 165)\n",
      "WordVectorizer:\n",
      "(2499, 57278)\n",
      "DomainVectorizer:\n",
      "(2499, 157)\n",
      "WordVectorizer:\n",
      "(2501, 58137)\n",
      "DomainVectorizer:\n",
      "(2501, 153)\n",
      "WordVectorizer:\n",
      "(2501, 58492)\n",
      "DomainVectorizer:\n",
      "(2501, 170)\n",
      "WordVectorizer:\n",
      "(10003, 57929)\n",
      "DomainVectorizer:\n",
      "(10003, 167)\n",
      "WordVectorizer:\n",
      "(2498, 57929)\n",
      "DomainVectorizer:\n",
      "(2498, 167)\n",
      "0.853034443257\n",
      "0:03:12.789926\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('words', WordVect()),\n",
    "        ('domain', Domain())\n",
    "  ])),\n",
    "  ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569940582322\n",
      "0:03:00.713157\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer(stop_words='english'))\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text['cleaned_text'], pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.461698717961\n",
      "0:00:44.510973\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer(stop_words='english'))\n",
    "  ])),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text['cleaned_text'], pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62386386678\n",
      "0:21:44.069018\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "        ('counts', CountVectorizer(ngram_range=(1, 2), min_df=3))\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text['cleaned_text'], pld_text.political_lean, cv=5, scoring='accuracy').mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipe(col):\n",
    "    time = datetime.datetime.now()\n",
    "    pld_issue = pld_text[pld_text.issue == col]\n",
    "    if pld_issue['cleaned_text'].count() > 5:\n",
    "        pipe = Pipeline([\n",
    "          ('features', FeatureUnion([\n",
    "                ('counts', CountVectorizer())\n",
    "          ])),\n",
    "          ('logreg', LogisticRegression())\n",
    "        ])\n",
    "        print \" \"\n",
    "        print \"issue: \" + str(col)\n",
    "        print cross_val_score(pipe, pld_issue['cleaned_text'], pld_issue.political_lean, cv=5, scoring='accuracy').mean()\n",
    "        print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "issue: abortion\n",
      "0.460374396135\n",
      "0:00:01.158694\n",
      " \n",
      "issue: asia\n",
      "0.269761904762\n",
      "0:00:00.278807\n",
      " \n",
      "issue: campaign-finance\n",
      "0.548534798535\n",
      "0:00:00.394141\n",
      " \n",
      "issue: civil-rights\n",
      "0.436969657875\n",
      "0:00:02.179912\n",
      " \n",
      "issue: cia\n",
      "0.534017094017\n",
      "0:00:00.557582\n",
      " \n",
      "issue: foreign-policy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45219279201\n",
      "0:00:03.083598\n",
      " \n",
      "issue: gay-rights\n",
      "0.393599336178\n",
      "0:00:01.971592\n",
      " \n",
      "issue: us-congress\n",
      "0.494039294039\n",
      "0:00:01.897374\n",
      " \n",
      "issue: us-house-representatives\n",
      "0.410714285714\n",
      "0:00:01.366856\n",
      " \n",
      "issue: criminal-justice\n",
      "0.488528138528\n",
      "0:00:00.401921\n",
      " \n",
      "issue: defense\n",
      "0.413758912656\n",
      "0:00:00.986979\n",
      " \n",
      "issue: democrat-party\n",
      "0.490361812101\n",
      "0:00:00.780160\n",
      " \n",
      "issue: education\n",
      "0.410294473377\n",
      "0:00:02.571426\n",
      " \n",
      "issue: domestic-policy\n",
      "0.273333333333\n",
      "0:00:00.108451\n",
      " \n",
      "issue: economic-policy\n",
      "0.406415954416\n",
      "0:00:00.957803\n",
      " \n",
      "issue: elections\n",
      "0.574809067416\n",
      "0:00:03.228309\n",
      " \n",
      "issue: election-2012\n",
      "0.591405090095\n",
      "0:00:47.487605\n",
      " \n",
      "issue: economy-jobs\n",
      "0.560315790971\n",
      "0:00:03.873658\n",
      " \n",
      "issue: economic-policy-debt-deficit\n",
      "0.572712600216\n",
      "0:00:05.733343\n",
      " \n",
      "issue: environment\n",
      "0.445716345659\n",
      "0:00:02.601595\n",
      " \n",
      "issue: free-speech\n",
      "0.406666666667\n",
      "0:00:00.391962\n",
      " \n",
      "issue: gun-legislation\n",
      "0.469886876366\n",
      "0:00:04.977387\n",
      " \n",
      "issue: immigration\n",
      "0.550232077636\n",
      "0:00:05.082927\n",
      " \n",
      "issue: energy\n",
      "0.386260683761\n",
      "0:00:00.553614\n",
      " \n",
      "issue: justice\n",
      "0.52871040724\n",
      "0:00:01.224292\n",
      " \n",
      "issue: marijuana-legalization\n",
      "0.444921126345\n",
      "0:00:00.530547\n",
      " \n",
      "issue: healthcare-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=5.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.602989695589\n",
      "0:00:07.744309\n",
      " \n",
      "issue: israel\n",
      "0.531944444444\n",
      "0:00:00.497304\n",
      " \n",
      "issue: labor\n",
      "0.483888888889\n",
      "0:00:00.221904\n",
      " \n",
      "issue: media-watchmedia-bias\n",
      "0.55697252733\n",
      "0:00:03.642402\n",
      " \n",
      "issue: medicare\n",
      "0.508441558442\n",
      "0:00:00.373096\n",
      " \n",
      "issue: middle-east\n",
      "0.452151990145\n",
      "0:00:01.685291\n"
     ]
    }
   ],
   "source": [
    "top_six_cols = pld_text.issue.unique()  #['election-2012', 'healthcare-0', 'immigration', 'economic-policy-debt-deficit', 'economy-jobs', 'gun-legislation']\n",
    "for col in top_six_cols:\n",
    "    pipe(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GetText(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        domains = X.cleaned_text\n",
    "        return domains\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.604970517794\n",
      "0:00:38.221002\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer())\n",
    "    ])),\n",
    "    ('domain', Domain())\n",
    "  ])),\n",
    "  ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853034443257\n",
      "0:03:16.615209\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer())\n",
    "    ])),\n",
    "    ('domain', Domain())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853834539577\n",
      "0:03:34.059663\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(min_df=4))\n",
    "    ])),\n",
    "    ('domain', Domain())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825038082707\n",
      "0:15:43.350393\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(ngram_range=(1, 2), min_df=2))\n",
    "    ])),\n",
    "    ('domain', Domain())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.829117092128\n",
      "0:11:23.004279\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(ngram_range=(1, 2), min_df=4))\n",
    "    ])),\n",
    "    ('domain', Domain())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827037699142\n",
      "0:14:29.761025\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(ngram_range=(1, 2), min_df=3))\n",
    "    ])),\n",
    "    ('domain', Domain())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819597408492\n",
      "0:24:33.104491\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(ngram_range=(1, 3), min_df=4))\n",
    "    ])),\n",
    "    ('domain', Domain())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Issue(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        domains = self.vect.transform(X.issue)\n",
    "        return domains\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.vect = CountVectorizer(**fit_params)\n",
    "        self.vect.fit(X['issue'])\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853674571513\n",
      "0:03:12.073189\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(min_df=4, max_features=25000))\n",
    "    ])),\n",
    "    ('domain', Domain())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852394251154\n",
      "0:02:20.039432\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(min_df=4))\n",
    "    ])),\n",
    "    ('domain', Domain()),\n",
    "    ('issue', Issue())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Url(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        domains = self.vect.transform(X.url_raw)\n",
    "        return domains\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.vect = CountVectorizer(**fit_params)\n",
    "        self.vect.fit(X['url_raw'])\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.900953915603\n",
      "0:03:05.730800\n"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(min_df=4))\n",
    "    ])),\n",
    "    ('domain', Domain()),\n",
    "    ('url', Url())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pld_text['cleaned_text_length'] = pld_text['cleaned_text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85488"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pld_text.cleaned_text_length.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordCount(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        count = X.cleaned_text_length\n",
    "        return count\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sentiment(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        sentiment = self.vect.transform(X.sentiment)\n",
    "        return sentiment\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.vect = CountVectorizer(**fit_params)\n",
    "        self.vect.fit(X['sentiment'])\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/stanleystevensWhistle/miniconda2/envs/sta...lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x1020d9030, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/stanleystevensWhistle/miniconda2/envs/sta...lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/stanl...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/stanleystevensWhistle/miniconda2/envs/sta...lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x1020d9030, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/stanleystevensWhistle/miniconda2/envs/sta...lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/stanl...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    648 \n    649         If a global instance already exists, this reinitializes and starts it\n    650         \"\"\"\n    651         app = cls.instance(**kwargs)\n    652         app.initialize(argv)\n--> 653         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    654 \n    655 #-----------------------------------------------------------------------------\n    656 # utility functions, for convenience\n    657 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'time = datetime.datetime.now()\\n\\npipe = Pipeline(...=-1).mean()\\n\\nprint datetime.datetime.now() - time', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-11-30T17:04:58.511020', 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'session': '5CAEA0B28E1A449DA1D15902359839D5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['5CAEA0B28E1A449DA1D15902359839D5']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'time = datetime.datetime.now()\\n\\npipe = Pipeline(...=-1).mean()\\n\\nprint datetime.datetime.now() - time', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-11-30T17:04:58.511020', 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'session': '5CAEA0B28E1A449DA1D15902359839D5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['5CAEA0B28E1A449DA1D15902359839D5'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'time = datetime.datetime.now()\\n\\npipe = Pipeline(...=-1).mean()\\n\\nprint datetime.datetime.now() - time', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-11-30T17:04:58.511020', 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'session': '5CAEA0B28E1A449DA1D15902359839D5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Print object>, <_ast.Print object>], cell_name='<ipython-input-123-9484b6344e1d>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 1382f9d50, execution_..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1383277b0, file \"<ipython-input-123-9484b6344e1d>\", line 16>\n        result = <ExecutionResult object at 1382f9d50, execution_..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1383277b0, file \"<ipython-input-123-9484b6344e1d>\", line 16>, result=<ExecutionResult object at 1382f9d50, execution_..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1383277b0, file \"<ipython-input-123-9484b6344e1d>\", line 16>\n        self.user_global_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Domain': <class '__main__.Domain'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GetText': <class '__main__.GetText'>, 'Goose': <class 'goose.Goose'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"from goose import Goose\\nimport pandas as pd\\n...etime\\nget_ipython().magic(u'matplotlib inline')\", u\"pld = pd.read_csv('0_16000.csv')\", u\"# del pld['Unnamed: 0']\\n# pld.head()\\n# cols ...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"del pld['Unnamed: 0']\\n# pld.head()\\n# cols = ...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"# del pld['Unnamed: 0']\\npld.columns = ['url_r...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"pld_text = pld[pld['cleaned_text'].notnull()]\\...n', 'political_lean', 'issue', 'title']].count()\", u\"top_six_cols = pld_text.columns  #['election-2... in top_six_cols:\\n#     pipe(col)\\ntop_six_cols\", u\"top_six_cols = pld_text.columns  #['election-2...p_six_cols:\\n#     pipe(col)\\npld_text['issues']\", u\"top_six_cols = pld_text.columns  #['election-2...op_six_cols:\\n#     pipe(col)\\npld_text['issue']\", u\"top_six_cols = pld_text.columns  #['election-2...   pipe(col)\\npld_text['issue'].groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...ols:\\n#     pipe(col)\\npld_text.groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...:\\n#     pipe(col)\\npld_text.groupby('issue')[0]\", u\"top_six_cols = pld_text.columns  #['election-2...ols:\\n#     pipe(col)\\npld_text.groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", u\"top_six_cols = pld_text.columns  #['election-2... pipe(col)\\npld_text.groupby('issue').count()[0]\", u\"top_six_cols = pld_text.columns  #['election-2... pipe(col)\\npld_text.groupby('issue').count()[1]\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", u\"top_six_cols = pld_text.columns  #['election-2...col)\\npld_text.groupby('issue').count()['issue']\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", ...], 'Issue': <class '__main__.Issue'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, ...}\n        self.user_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Domain': <class '__main__.Domain'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GetText': <class '__main__.GetText'>, 'Goose': <class 'goose.Goose'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"from goose import Goose\\nimport pandas as pd\\n...etime\\nget_ipython().magic(u'matplotlib inline')\", u\"pld = pd.read_csv('0_16000.csv')\", u\"# del pld['Unnamed: 0']\\n# pld.head()\\n# cols ...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"del pld['Unnamed: 0']\\n# pld.head()\\n# cols = ...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"# del pld['Unnamed: 0']\\npld.columns = ['url_r...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"pld_text = pld[pld['cleaned_text'].notnull()]\\...n', 'political_lean', 'issue', 'title']].count()\", u\"top_six_cols = pld_text.columns  #['election-2... in top_six_cols:\\n#     pipe(col)\\ntop_six_cols\", u\"top_six_cols = pld_text.columns  #['election-2...p_six_cols:\\n#     pipe(col)\\npld_text['issues']\", u\"top_six_cols = pld_text.columns  #['election-2...op_six_cols:\\n#     pipe(col)\\npld_text['issue']\", u\"top_six_cols = pld_text.columns  #['election-2...   pipe(col)\\npld_text['issue'].groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...ols:\\n#     pipe(col)\\npld_text.groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...:\\n#     pipe(col)\\npld_text.groupby('issue')[0]\", u\"top_six_cols = pld_text.columns  #['election-2...ols:\\n#     pipe(col)\\npld_text.groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", u\"top_six_cols = pld_text.columns  #['election-2... pipe(col)\\npld_text.groupby('issue').count()[0]\", u\"top_six_cols = pld_text.columns  #['election-2... pipe(col)\\npld_text.groupby('issue').count()[1]\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", u\"top_six_cols = pld_text.columns  #['election-2...col)\\npld_text.groupby('issue').count()['issue']\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", ...], 'Issue': <class '__main__.Issue'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Users/stanleystevensWhistle/Develop/data_science/sfdat28-stevens/projects/political_lean/<ipython-input-123-9484b6344e1d> in <module>()\n     11     ('wordcount', WordCount())\n     12   ])),\n     13   ('logreg', LogisticRegression())\n     14 ])\n     15 \n---> 16 print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n     17 \n     18 print datetime.datetime.now() - time\n     19 \n     20 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/cross_validation.py in cross_val_score(estimator=Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...                 711  \n\n[12501 rows x 10 columns], y=0        Lean Left\n1             Left\n2        L...       Center\nName: political_lean, dtype: object, scoring='accuracy', cv=sklearn.cross_validation.StratifiedKFold(labels=...r'], n_folds=5, shuffle=False, random_state=None), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n   1428     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n   1429                         pre_dispatch=pre_dispatch)\n   1430     scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n   1431                                               train, test, verbose, None,\n   1432                                               fit_params)\n-> 1433                       for train, test in cv)\n        cv = sklearn.cross_validation.StratifiedKFold(labels=...r'], n_folds=5, shuffle=False, random_state=None)\n   1434     return np.array(scores)[:, 0]\n   1435 \n   1436 \n   1437 class FitFailedWarning(RuntimeWarning):\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Nov 30 17:05:16 2016\nPID: 12366Python 2.7.12: /Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/bin/python\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...                 711  \n\n[12501 rows x 10 columns], 0        Lean Left\n1             Left\n2        L...       Center\nName: political_lean, dtype: object, make_scorer(accuracy_score), array([ 1259,  1260,  1597, ..., 12498, 12499, 12500]), array([   0,    1,    2, ..., 2570, 2579, 2821]), 0, None, None)\n        kwargs = {}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...                 711  \n\n[12501 rows x 10 columns], 0        Lean Left\n1             Left\n2        L...       Center\nName: political_lean, dtype: object, make_scorer(accuracy_score), array([ 1259,  1260,  1597, ..., 12498, 12499, 12500]), array([   0,    1,    2, ..., 2570, 2579, 2821]), 0, None, None), {})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...                 711  \n\n[12501 rows x 10 columns], y=0        Lean Left\n1             Left\n2        L...       Center\nName: political_lean, dtype: object, scorer=make_scorer(accuracy_score), train=array([ 1259,  1260,  1597, ..., 12498, 12499, 12500]), test=array([   0,    1,    2, ..., 2570, 2579, 2821]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...                  711  \n\n[9999 rows x 10 columns]\n        y_train = 1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...                  711  \n\n[9999 rows x 10 columns], y=1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object, **fit_params={})\n    159             pipeline.\n    160         y : iterable, default=None\n    161             Training targets. Must fulfill label requirements for all steps of\n    162             the pipeline.\n    163         \"\"\"\n--> 164         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...                  711  \n\n[9999 rows x 10 columns]\n        y = 1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object\n    165         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    166         return self\n    167 \n    168     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...                  711  \n\n[9999 rows x 10 columns], y=1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object, **fit_params={})\n    140             step, param = pname.split('__', 1)\n    141             fit_params_steps[step][param] = pval\n    142         Xt = X\n    143         for name, transform in self.steps[:-1]:\n    144             if hasattr(transform, \"fit_transform\"):\n--> 145                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt =                                                 ...                  711  \n\n[9999 rows x 10 columns]\n        transform.fit_transform = <bound method FeatureUnion.fit_transform of Feat...0x1382539d0>)],\n       transformer_weights=None)>\n        y = 1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object\n        fit_params_steps = {'features': {}, 'logreg': {}}\n        name = 'features'\n    146             else:\n    147                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    148                               .transform(Xt)\n    149         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[... 0x1382539d0>)],\n       transformer_weights=None), X=                                                ...                  711  \n\n[9999 rows x 10 columns], y=1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object, **fit_params={})\n    497             for name, trans in self.transformer_list)\n    498 \n    499         Xs, transformers = zip(*result)\n    500         self._update_transformer_list(transformers)\n    501         if any(sparse.issparse(f) for f in Xs):\n--> 502             Xs = sparse.hstack(Xs).tocsr()\n        Xs = (<9999x26818 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, <9999x165 sparse matrix of type '<type 'numpy.in... stored elements in Compressed Sparse Row format>, <9999x16532 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, 1686      2940\n1687      1938\n2153       248\n291...      711\nName: cleaned_text_length, dtype: int64)\n        Xs.tocsr = undefined\n    503         else:\n    504             Xs = np.hstack(Xs)\n    505         return Xs\n    506 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/scipy/sparse/construct.py in hstack(blocks=(<9999x26818 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, <9999x165 sparse matrix of type '<type 'numpy.in... stored elements in Compressed Sparse Row format>, <9999x16532 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, 1686      2940\n1687      1938\n2153       248\n291...      711\nName: cleaned_text_length, dtype: int64), format=None, dtype=None)\n    459     >>> hstack([A,B]).toarray()\n    460     array([[1, 2, 5],\n    461            [3, 4, 6]])\n    462 \n    463     \"\"\"\n--> 464     return bmat([blocks], format=format, dtype=dtype)\n        blocks = (<9999x26818 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, <9999x165 sparse matrix of type '<type 'numpy.in... stored elements in Compressed Sparse Row format>, <9999x16532 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, 1686      2940\n1687      1938\n2153       248\n291...      711\nName: cleaned_text_length, dtype: int64)\n        format = None\n        dtype = None\n    465 \n    466 \n    467 def vstack(blocks, format=None, dtype=None):\n    468     \"\"\"\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/scipy/sparse/construct.py in bmat(blocks=array([[ <9999x26818 sparse matrix of type '<typ...d elements in COOrdinate format>]], dtype=object), format=None, dtype=None)\n    576 \n    577                 if brow_lengths[i] == 0:\n    578                     brow_lengths[i] = A.shape[0]\n    579                 elif brow_lengths[i] != A.shape[0]:\n    580                     raise ValueError('blocks[%d,:] has incompatible '\n--> 581                                      'row dimensions' % i)\n        i = 0\n    582 \n    583                 if bcol_lengths[j] == 0:\n    584                     bcol_lengths[j] = A.shape[1]\n    585                 elif bcol_lengths[j] != A.shape[1]:\n\nValueError: blocks[0,:] has incompatible row dimensions\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-9484b6344e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpld_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpld_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'political_lean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1433\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1434\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0;31m# a working pool as they expect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/Users/stanleystevensWhistle/miniconda2/envs/sta...lib/python2.7/site-packages/ipykernel/__main__.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = 'ipykernel'\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x1020d9030, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/stanleystevensWhistle/miniconda2/envs/sta...lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/stanl...python2.7/site-packages/ipykernel/kernelapp.pyc'>}, init_globals=None, mod_name='__main__', mod_fname='/Users/stanleystevensWhistle/miniconda2/envs/sta...lib/python2.7/site-packages/ipykernel/__main__.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='ipykernel')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x1020d9030, file \"/Use...2.7/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': None, '__file__': '/Users/stanleystevensWhistle/miniconda2/envs/sta...lib/python2.7/site-packages/ipykernel/__main__.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': 'ipykernel', 'app': <module 'ipykernel.kernelapp' from '/Users/stanl...python2.7/site-packages/ipykernel/kernelapp.pyc'>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    648 \n    649         If a global instance already exists, this reinitializes and starts it\n    650         \"\"\"\n    651         app = cls.instance(**kwargs)\n    652         app.initialize(argv)\n--> 653         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    654 \n    655 #-----------------------------------------------------------------------------\n    656 # utility functions, for convenience\n    657 #-----------------------------------------------------------------------------\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'time = datetime.datetime.now()\\n\\npipe = Pipeline(...=-1).mean()\\n\\nprint datetime.datetime.now() - time', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-11-30T17:04:58.511020', 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'session': '5CAEA0B28E1A449DA1D15902359839D5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['5CAEA0B28E1A449DA1D15902359839D5']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'time = datetime.datetime.now()\\n\\npipe = Pipeline(...=-1).mean()\\n\\nprint datetime.datetime.now() - time', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-11-30T17:04:58.511020', 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'session': '5CAEA0B28E1A449DA1D15902359839D5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['5CAEA0B28E1A449DA1D15902359839D5'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'time = datetime.datetime.now()\\n\\npipe = Pipeline(...=-1).mean()\\n\\nprint datetime.datetime.now() - time', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-11-30T17:04:58.511020', 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'session': '5CAEA0B28E1A449DA1D15902359839D5', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '7CB4AA7023F34B52ACA631F9812C0F01', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\",), **kwargs={'silent': False, 'store_history': True})\n    496             )\n    497         self.payload_manager.write_payload(payload)\n    498 \n    499     def run_cell(self, *args, **kwargs):\n    500         self._last_traceback = None\n--> 501         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\",)\n        kwargs = {'silent': False, 'store_history': True}\n    502 \n    503     def _showtraceback(self, etype, evalue, stb):\n    504         # try to preserve ordering of tracebacks and print statements\n    505         sys.stdout.flush()\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"time = datetime.datetime.now()\\n\\npipe = Pipel...).mean()\\n\\nprint datetime.datetime.now() - time\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Print object>, <_ast.Print object>], cell_name='<ipython-input-123-9484b6344e1d>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 1382f9d50, execution_..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x1383277b0, file \"<ipython-input-123-9484b6344e1d>\", line 16>\n        result = <ExecutionResult object at 1382f9d50, execution_..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x1383277b0, file \"<ipython-input-123-9484b6344e1d>\", line 16>, result=<ExecutionResult object at 1382f9d50, execution_..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x1383277b0, file \"<ipython-input-123-9484b6344e1d>\", line 16>\n        self.user_global_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Domain': <class '__main__.Domain'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GetText': <class '__main__.GetText'>, 'Goose': <class 'goose.Goose'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"from goose import Goose\\nimport pandas as pd\\n...etime\\nget_ipython().magic(u'matplotlib inline')\", u\"pld = pd.read_csv('0_16000.csv')\", u\"# del pld['Unnamed: 0']\\n# pld.head()\\n# cols ...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"del pld['Unnamed: 0']\\n# pld.head()\\n# cols = ...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"# del pld['Unnamed: 0']\\npld.columns = ['url_r...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"pld_text = pld[pld['cleaned_text'].notnull()]\\...n', 'political_lean', 'issue', 'title']].count()\", u\"top_six_cols = pld_text.columns  #['election-2... in top_six_cols:\\n#     pipe(col)\\ntop_six_cols\", u\"top_six_cols = pld_text.columns  #['election-2...p_six_cols:\\n#     pipe(col)\\npld_text['issues']\", u\"top_six_cols = pld_text.columns  #['election-2...op_six_cols:\\n#     pipe(col)\\npld_text['issue']\", u\"top_six_cols = pld_text.columns  #['election-2...   pipe(col)\\npld_text['issue'].groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...ols:\\n#     pipe(col)\\npld_text.groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...:\\n#     pipe(col)\\npld_text.groupby('issue')[0]\", u\"top_six_cols = pld_text.columns  #['election-2...ols:\\n#     pipe(col)\\npld_text.groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", u\"top_six_cols = pld_text.columns  #['election-2... pipe(col)\\npld_text.groupby('issue').count()[0]\", u\"top_six_cols = pld_text.columns  #['election-2... pipe(col)\\npld_text.groupby('issue').count()[1]\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", u\"top_six_cols = pld_text.columns  #['election-2...col)\\npld_text.groupby('issue').count()['issue']\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", ...], 'Issue': <class '__main__.Issue'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, ...}\n        self.user_ns = {'BeautifulSoup': <class 'bs4.BeautifulSoup'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Domain': <class '__main__.Domain'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GetText': <class '__main__.GetText'>, 'Goose': <class 'goose.Goose'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', u\"from goose import Goose\\nimport pandas as pd\\n...etime\\nget_ipython().magic(u'matplotlib inline')\", u\"pld = pd.read_csv('0_16000.csv')\", u\"# del pld['Unnamed: 0']\\n# pld.head()\\n# cols ...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"del pld['Unnamed: 0']\\n# pld.head()\\n# cols = ...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"# del pld['Unnamed: 0']\\npld.columns = ['url_r...'meta_description', 'cleaned_text']\\npld.head(3)\", u\"pld_text = pld[pld['cleaned_text'].notnull()]\\...n', 'political_lean', 'issue', 'title']].count()\", u\"top_six_cols = pld_text.columns  #['election-2... in top_six_cols:\\n#     pipe(col)\\ntop_six_cols\", u\"top_six_cols = pld_text.columns  #['election-2...p_six_cols:\\n#     pipe(col)\\npld_text['issues']\", u\"top_six_cols = pld_text.columns  #['election-2...op_six_cols:\\n#     pipe(col)\\npld_text['issue']\", u\"top_six_cols = pld_text.columns  #['election-2...   pipe(col)\\npld_text['issue'].groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...ols:\\n#     pipe(col)\\npld_text.groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...:\\n#     pipe(col)\\npld_text.groupby('issue')[0]\", u\"top_six_cols = pld_text.columns  #['election-2...ols:\\n#     pipe(col)\\npld_text.groupby('issue')\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", u\"top_six_cols = pld_text.columns  #['election-2... pipe(col)\\npld_text.groupby('issue').count()[0]\", u\"top_six_cols = pld_text.columns  #['election-2... pipe(col)\\npld_text.groupby('issue').count()[1]\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", u\"top_six_cols = pld_text.columns  #['election-2...col)\\npld_text.groupby('issue').count()['issue']\", u\"top_six_cols = pld_text.columns  #['election-2...    pipe(col)\\npld_text.groupby('issue').count()\", ...], 'Issue': <class '__main__.Issue'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Users/stanleystevensWhistle/Develop/data_science/sfdat28-stevens/projects/political_lean/<ipython-input-123-9484b6344e1d> in <module>()\n     11     ('wordcount', WordCount())\n     12   ])),\n     13   ('logreg', LogisticRegression())\n     14 ])\n     15 \n---> 16 print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n     17 \n     18 print datetime.datetime.now() - time\n     19 \n     20 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/cross_validation.py in cross_val_score(estimator=Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...                 711  \n\n[12501 rows x 10 columns], y=0        Lean Left\n1             Left\n2        L...       Center\nName: political_lean, dtype: object, scoring='accuracy', cv=sklearn.cross_validation.StratifiedKFold(labels=...r'], n_folds=5, shuffle=False, random_state=None), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n   1428     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n   1429                         pre_dispatch=pre_dispatch)\n   1430     scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n   1431                                               train, test, verbose, None,\n   1432                                               fit_params)\n-> 1433                       for train, test in cv)\n        cv = sklearn.cross_validation.StratifiedKFold(labels=...r'], n_folds=5, shuffle=False, random_state=None)\n   1434     return np.array(scores)[:, 0]\n   1435 \n   1436 \n   1437 class FitFailedWarning(RuntimeWarning):\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    805             if pre_dispatch == \"all\" or n_jobs == 1:\n    806                 # The iterable was consumed all at once by the above for loop.\n    807                 # No need to wait for async callbacks to trigger to\n    808                 # consumption.\n    809                 self._iterating = False\n--> 810             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    811             # Make sure that we get a last message telling us we are done\n    812             elapsed_time = time.time() - self._start_time\n    813             self._print('Done %3i out of %3i | elapsed: %s finished',\n    814                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Nov 30 17:05:16 2016\nPID: 12366Python 2.7.12: /Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/bin/python\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n     67     def __init__(self, iterator_slice):\n     68         self.items = list(iterator_slice)\n     69         self._size = len(self.items)\n     70 \n     71     def __call__(self):\n---> 72         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...                 711  \n\n[12501 rows x 10 columns], 0        Lean Left\n1             Left\n2        L...       Center\nName: political_lean, dtype: object, make_scorer(accuracy_score), array([ 1259,  1260,  1597, ..., 12498, 12499, 12500]), array([   0,    1,    2, ..., 2570, 2579, 2821]), 0, None, None)\n        kwargs = {}\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]),                                                 ...                 711  \n\n[12501 rows x 10 columns], 0        Lean Left\n1             Left\n2        L...       Center\nName: political_lean, dtype: object, make_scorer(accuracy_score), array([ 1259,  1260,  1597, ..., 12498, 12499, 12500]), array([   0,    1,    2, ..., 2570, 2579, 2821]), 0, None, None), {})]\n     73 \n     74     def __len__(self):\n     75         return self._size\n     76 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...                 711  \n\n[12501 rows x 10 columns], y=0        Lean Left\n1             Left\n2        L...       Center\nName: political_lean, dtype: object, scorer=make_scorer(accuracy_score), train=array([ 1259,  1260,  1597, ..., 12498, 12499, 12500]), test=array([   0,    1,    2, ..., 2570, 2579, 2821]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, error_score='raise')\n   1526 \n   1527     try:\n   1528         if y_train is None:\n   1529             estimator.fit(X_train, **fit_params)\n   1530         else:\n-> 1531             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('....0001,\n          verbose=0, warm_start=False))])>\n        X_train =                                                 ...                  711  \n\n[9999 rows x 10 columns]\n        y_train = 1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object\n        fit_params = {}\n   1532 \n   1533     except Exception as e:\n   1534         if error_score == 'raise':\n   1535             raise\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...                  711  \n\n[9999 rows x 10 columns], y=1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object, **fit_params={})\n    159             pipeline.\n    160         y : iterable, default=None\n    161             Training targets. Must fulfill label requirements for all steps of\n    162             the pipeline.\n    163         \"\"\"\n--> 164         Xt, fit_params = self._pre_transform(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._pre_transform = <bound method Pipeline._pre_transform of Pipelin....0001,\n          verbose=0, warm_start=False))])>\n        X =                                                 ...                  711  \n\n[9999 rows x 10 columns]\n        y = 1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object\n    165         self.steps[-1][-1].fit(Xt, y, **fit_params)\n    166         return self\n    167 \n    168     def fit_transform(self, X, y=None, **fit_params):\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/pipeline.py in _pre_transform(self=Pipeline(steps=[('features', FeatureUnion(n_jobs...0.0001,\n          verbose=0, warm_start=False))]), X=                                                ...                  711  \n\n[9999 rows x 10 columns], y=1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object, **fit_params={})\n    140             step, param = pname.split('__', 1)\n    141             fit_params_steps[step][param] = pval\n    142         Xt = X\n    143         for name, transform in self.steps[:-1]:\n    144             if hasattr(transform, \"fit_transform\"):\n--> 145                 Xt = transform.fit_transform(Xt, y, **fit_params_steps[name])\n        Xt =                                                 ...                  711  \n\n[9999 rows x 10 columns]\n        transform.fit_transform = <bound method FeatureUnion.fit_transform of Feat...0x1382539d0>)],\n       transformer_weights=None)>\n        y = 1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object\n        fit_params_steps = {'features': {}, 'logreg': {}}\n        name = 'features'\n    146             else:\n    147                 Xt = transform.fit(Xt, y, **fit_params_steps[name]) \\\n    148                               .transform(Xt)\n    149         return Xt, fit_params_steps[self.steps[-1][0]]\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[... 0x1382539d0>)],\n       transformer_weights=None), X=                                                ...                  711  \n\n[9999 rows x 10 columns], y=1686          Mixed\n1687          Mixed\n2153    ...       Center\nName: political_lean, dtype: object, **fit_params={})\n    497             for name, trans in self.transformer_list)\n    498 \n    499         Xs, transformers = zip(*result)\n    500         self._update_transformer_list(transformers)\n    501         if any(sparse.issparse(f) for f in Xs):\n--> 502             Xs = sparse.hstack(Xs).tocsr()\n        Xs = (<9999x26818 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, <9999x165 sparse matrix of type '<type 'numpy.in... stored elements in Compressed Sparse Row format>, <9999x16532 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, 1686      2940\n1687      1938\n2153       248\n291...      711\nName: cleaned_text_length, dtype: int64)\n        Xs.tocsr = undefined\n    503         else:\n    504             Xs = np.hstack(Xs)\n    505         return Xs\n    506 \n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/scipy/sparse/construct.py in hstack(blocks=(<9999x26818 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, <9999x165 sparse matrix of type '<type 'numpy.in... stored elements in Compressed Sparse Row format>, <9999x16532 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, 1686      2940\n1687      1938\n2153       248\n291...      711\nName: cleaned_text_length, dtype: int64), format=None, dtype=None)\n    459     >>> hstack([A,B]).toarray()\n    460     array([[1, 2, 5],\n    461            [3, 4, 6]])\n    462 \n    463     \"\"\"\n--> 464     return bmat([blocks], format=format, dtype=dtype)\n        blocks = (<9999x26818 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, <9999x165 sparse matrix of type '<type 'numpy.in... stored elements in Compressed Sparse Row format>, <9999x16532 sparse matrix of type '<type 'numpy.... stored elements in Compressed Sparse Row format>, 1686      2940\n1687      1938\n2153       248\n291...      711\nName: cleaned_text_length, dtype: int64)\n        format = None\n        dtype = None\n    465 \n    466 \n    467 def vstack(blocks, format=None, dtype=None):\n    468     \"\"\"\n\n...........................................................................\n/Users/stanleystevensWhistle/miniconda2/envs/stanleyyork/lib/python2.7/site-packages/scipy/sparse/construct.py in bmat(blocks=array([[ <9999x26818 sparse matrix of type '<typ...d elements in COOrdinate format>]], dtype=object), format=None, dtype=None)\n    576 \n    577                 if brow_lengths[i] == 0:\n    578                     brow_lengths[i] = A.shape[0]\n    579                 elif brow_lengths[i] != A.shape[0]:\n    580                     raise ValueError('blocks[%d,:] has incompatible '\n--> 581                                      'row dimensions' % i)\n        i = 0\n    582 \n    583                 if bcol_lengths[j] == 0:\n    584                     bcol_lengths[j] = A.shape[1]\n    585                 elif bcol_lengths[j] != A.shape[1]:\n\nValueError: blocks[0,:] has incompatible row dimensions\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "time = datetime.datetime.now()\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('features', FeatureUnion([\n",
    "    ('word', Pipeline([\n",
    "      ('gettext', GetText()),\n",
    "      ('counts', CountVectorizer(min_df=4))\n",
    "    ])),\n",
    "    ('domain', Domain()),\n",
    "    ('url', Url()),\n",
    "    ('sentiment', Sentiment())\n",
    "  ])),\n",
    "  ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "print cross_val_score(pipe, pld_text, pld_text['political_lean'], cv=5, scoring='accuracy', n_jobs=-1).mean()\n",
    "\n",
    "print datetime.datetime.now() - time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:stanleyyork]",
   "language": "python",
   "name": "conda-env-stanleyyork-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
